\section{System Design}
\label{sec:design}

This section details the architecture of GPU-Fuzz. As illustrated in Figure~\ref{fig:arch}, the system is designed around a data flow that seamlessly connects constraint-based test case generation with cross-framework execution, monitoring, and log-based reproduction.

\begin{figure}[htbp]
	\centering
	\resizebox{0.7\linewidth}{!}{
	\begin{tikzpicture}[
		node distance=1.5cm,
		% Styles
		box/.style={rectangle, draw=black, thick, fill=white, minimum height=1.2cm, text width=4.5cm, text centered},
		artifact/.style={box, fill=black!5, rounded corners},
		final_artifact/.style={artifact, fill=black!15},
		arrow/.style={->, >=stealth, thick}
	]

	% --- Main linear flow ---
	\node[box] (fuzz_engine) {Fuzzing Engine};
	\node[artifact] (param_config) [below=of fuzz_engine] {Parameter Configuration};
	\node[box] (materializer) [below=of param_config] {Test Case Materializer};
	\node[artifact] (concrete_test_case) [below=of materializer] {Concrete Test Case};

	% --- Execution side-branch ---
	\node[box] (gpu) [right=3cm of concrete_test_case] {GPU Hardware};
	\node[box] (oracle) [above=of gpu] {Runtime Analysis Tool};

	% --- Final output ---
	\node[final_artifact] (reproducer) [below=2.5cm of concrete_test_case] {Standalone Reproducer};

	% --- ARROWS ---
	% Main data flow
	\draw[arrow] (fuzz_engine) -- (param_config);
	\draw[arrow] (param_config) -- (materializer);
	\draw[arrow] (materializer) -- (concrete_test_case);

	% Execution flow
	\draw[arrow] (concrete_test_case) -- (gpu);
	\draw[arrow] (oracle) -- (gpu) node[midway, right] {Monitors};
	
	% Connection to reproducer
	\draw[arrow] (concrete_test_case) -- (reproducer);

	\end{tikzpicture}
	} % end of resizebox
	\caption{The architecture of the GPU-Fuzz system.}
	\label{fig:arch}
\end{figure}

\subsection{Constraint Library and Operator Modeling}
The foundation of GPU-Fuzz is its ability to generate semantically valid inputs. This is achieved through a Constraint Library that models the operational semantics of deep learning operators. For each target operator (e.g., convolution, pooling, matrix multiplication), we define a set of constraints that capture the legitimate relationships between its parameters, such as tensor shapes, data types, kernel sizes, strides, and padding. These constraints create a framework-agnostic representation of the operator's contract. This approach ensures that any test case generated is, by construction, guaranteed to pass the framework's initial validation checks.

\subsection{Constraint-based Test Case Generation}
The core of the fuzzing loop resides in the test case generator. The process begins by randomly selecting an operator template from the Constraint Library. The generator then populates the template with randomized, but plausible, target dimensions and parameters. These parameters, along with the operator's formal constraints, are passed to a constraint solver. The solver's task is to find a concrete assignment of values that satisfies all constraints. The result is a complete set of valid parameters (e.g., \texttt{input\_shape}, \texttt{kernel\_size}, \texttt{stride}) and the corresponding output tensor shape, which together form a framework-agnostic parameter configuration.

For instance, consider a 2D convolution (\texttt{Conv2D}). The relationship between input height ($H_{in}$), output height ($H_{out}$), padding ($P$), kernel ($K$), dilation ($D$), and stride ($S$) is governed by the equation: $H_{out} = \lfloor (H_{in} + 2P - D \cdot (K - 1) - 1) / S \rfloor + 1$. Furthermore, for grouped convolutions, the number of input and output channels must both be divisible by the `groups` parameter. Our fuzzer translates these rules into a formal constraint system. It might generate a plausible $H_{in}$ and then task the solver with finding a consistent set of values for the remaining parameters that satisfy all interdependent constraints. This ensures the generated parameters are holistically consistent, a prerequisite for bypassing framework validation and testing the underlying kernel.

\subsection{Cross-Framework Execution and Monitoring}
Once a set of valid parameters is generated, this parameter configuration is materialized into an executable script for a target framework (PyTorch, TensorFlow, or PaddlePaddle). This script creates the necessary tensors, populates them with random data, and invokes the operator on the GPU.

The execution is monitored by NVIDIA's \texttt{compute-sanitizer}. This tool can detect a wide range of GPU-level errors, such as out-of-bounds memory accesses and race conditions, that would not typically cause a visible crash at the Python API level. When a violation is detected, \texttt{compute-sanitizer} terminates the process and generates a detailed report, which serves as our primary bug oracle.

\subsection{Bug Reproducibility}
To facilitate the validation and debugging of discovered vulnerabilities, \textsc{Gpu-Fuzz} systematically records the conditions that trigger each failure. This record encapsulates the target operator and framework, the specific input parameters (e.g., kernel size, stride), the shapes of all input tensors, and the random seed used for data generation. The raw input tensors are also preserved. This collection of artifacts provides a self-contained and deterministic reproducer for each bug, significantly simplifying the process of verification and root cause analysis for developers.