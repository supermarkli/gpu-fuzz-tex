\section{Evaluation}
\label{sec:eval}

In this section, we evaluate the effectiveness and efficiency of \textsc{GPU-Fuzz}. We aim to answer the following research questions (RQs):
\begin{itemize}[leftmargin=1em]
    \item \textbf{RQ1:} How effective is \textsc{GPU-Fuzz} in uncovering real-world bugs in major deep learning frameworks?
    \item \textbf{RQ2:} How does \textsc{GPU-Fuzz} compare with state-of-the-art DL fuzzers in terms of test case generation and bug discovery, particularly for GPU memory errors?
\end{itemize}

\subsection{Experimental Setup}
\label{sec:setup}
All experiments were conducted on a server with the configuration detailed in \T~\ref{tbl:setup}. We established isolated Conda environments for each of the three target frameworks (PyTorch, TensorFlow, and PaddlePaddle) to manage their specific dependencies. The core hardware, operating system, and NVIDIA driver were consistent across all tests.

\begin{table}[h!]
\centering
\caption{Experimental Environment Configuration.}
\label{tbl:setup}
\footnotesize
\begin{tabular}{@{}ll@{}}
\toprule
\textbf{Component} & \textbf{Specification} \\ \midrule
\multicolumn{2}{@{}l}{\textbf{Hardware}} \\
\hspace{1em}CPU & 2 x Intel Xeon Silver 4510 \\
\hspace{1em}GPU & NVIDIA H100 PCIe \\
\midrule
\multicolumn{2}{@{}l}{\textbf{Software}} \\
\hspace{1em}Operating System & Ubuntu 24.04.2 LTS \\
\hspace{1em}NVIDIA Driver & 580.82.07 \\
\hspace{1em}CUDA Runtime & 12.8.93 \\
\hspace{1em}Python & 3.11.13 \\
\midrule
\multicolumn{2}{@{}l}{\textbf{Frameworks}} \\
\hspace{1em}PyTorch & PyTorch 2.3.1+cu121 with cuDNN 8.9.2.26 \\
\hspace{1em}TensorFlow & 2.20.0, with cuDNN 9.13.0.50 \\
\hspace{1em}PaddlePaddle & 2.6.1 \\
\bottomrule
\end{tabular}%
\end{table}

\subsection{Bug Discovery Effectiveness}

Over the course of our evaluation, \textsc{GPU-Fuzz} uncovered a total of 13 previously unknown bugs across the three frameworks. \T~\ref{tbl:bugs} presents a summary of these findings. The bugs span a range of failure modes, from low-level memory corruption to API-level exceptions. 
We identified 7 distinct memory access violations (e.g., out-of-bounds or misaligned writes). Among these, 5 were silent memory corruptions that do not trigger any API-level crash and are only detectable with specialized tools like compute-sanitizer~\cite{nvidia2023compsan}. 

\begin{table*}[htbp]
\centering
\caption{Summary of Bugs Discovered by \textsc{GPU-Fuzz}.}
\label{tbl:bugs}
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}lllllll@{}}
\toprule
\textbf{ID} & \textbf{Framework} & \textbf{Operator} & \textbf{Bug Type} & \textbf{Root Cause} & \textbf{Failure Mode} & \textbf{Status} \\ \midrule
\textbf{Bug\textsubscript{1}} & PyTorch & \texttt{conv\_transpose2d} & OOB Global Write & Incorrect grid dimension calculation & GPU-Level Exception (CUBLAS) & Confirmed \\
\textbf{Bug\textsubscript{2}} & PyTorch & \texttt{bmm\_sparse} & Misaligned Global Write & Incorrect pointer arithmetic in CUSPARSE & Silent Memory Corruption & Reported \\
\textbf{Bug\textsubscript{3}} & PyTorch & \texttt{adaptive\_avg\_pool2d} & OOB Global Write & Flawed boundary checks in CUDA kernel & Silent Memory Corruption & Confirmed \\
\textbf{Bug\textsubscript{4}} & PyTorch & \texttt{replication\_pad2d} & OOB Global Write & Incorrect grid dimension calculation & Silent Memory Corruption & Confirmed \\
\textbf{Bug\textsubscript{5}} & PyTorch & \texttt{adaptive\_max\_pool2d} & OOB Global Write & Flawed boundary checks in CUDA kernel & Silent Memory Corruption & Confirmed \\
\textbf{Bug\textsubscript{6}} & PyTorch & \texttt{conv\_transpose3d} & OOB Shared Read & Incorrect index calculation for shared memory & Silent Memory Corruption & Fixed \\
\textbf{Bug\textsubscript{7}} & PyTorch & \texttt{reflection\_pad1d} & Invalid Launch Config & Integer overflow in \texttt{torch.compile} symint logic & GPU-Level Exception (CUDA) & Confirmed \\
\textbf{Bug\textsubscript{8}} & TensorFlow & \texttt{Conv2D} & OOB Global Read & Incorrect index calculation in kernel & Silent Read / Downstream Crash & Confirmed \\
\textbf{Bug\textsubscript{9}} & TensorFlow & \texttt{Conv2D} & Integer Overflow & Overflow in launch config calculation & CPU-Side Assert & Confirmed \\
\textbf{Bug\textsubscript{10}} & PaddlePaddle & \texttt{conv2d\_transpose} & Precondition Violation & Integer overflow in tensor dimension calculation & CPU-Side Assert & Confirmed \\
\textbf{Bug\textsubscript{11}} & PaddlePaddle & \texttt{conv3d\_transpose} & Illegal Instruction & Invalid parameters passed to cuDNN kernel & GPU-Level Exception (cuDNN) & Confirmed \\
\textbf{Bug\textsubscript{12}} & PaddlePaddle & \texttt{conv2d\_transpose} & Bad API Parameter & Invalid parameter combination passed to cuDNN & GPU-Level Exception (cuDNN) & Confirmed \\
\textbf{Bug\textsubscript{13}} & PaddlePaddle & \texttt{conv2d\_transpose} & Invalid Launch Config & Incorrect grid/block dimension calculation & GPU-Level Exception (CUDA) & Confirmed \\
\bottomrule
\end{tabular}
}
\end{table*}

\parh{Bug Patterns.} 
Our findings reveal important patterns across three distinct failure modes:
\begin{itemize}[leftmargin=1em]
    \item \textbf{Silent Memory Corruption:} The most critical category, where out-of-bounds or misaligned memory access occurs without causing any API-level error. These are the most insidious bugs as they can lead to silent data corruption and are only detectable with low-level memory debuggers.
    \item \textbf{GPU-Level Exceptions:} The second category, where invalid parameters or configurations cause CUDA, cuDNN, or CUBLAS libraries to return an error, which is then typically caught and reported by the framework.
    \item \textbf{CPU-Side Asserts:} The final category, where issues like integer overflows occur on the CPU during the calculation of kernel parameters, preventing the GPU launch altogether.
\end{itemize}
\noindent A common root cause across all frameworks was incorrect grid dimension calculations or flawed boundary checks, with transposed convolutions being particularly error-prone. 

\subsection{Comparative Study}
\label{sec:comparison}
To quantitatively validate our approach, we conducted a comparative study against NNSmith~\cite{liu2023nnsmith}, a state-of-the-art DL fuzzer. We conducted five independent 4-hour fuzzing runs for each tool on the same hardware targeting PyTorch, with both tools running in identical Conda environments.

\T~\ref{tbl:comparison} summarizes the results. NNSmith generated on average $19{,}063\pm 360$ test cases and uncovered $296\pm 19$ bugs. Most of its findings are numerical mismatches rather than memory-safety issues. In contrast, \textsc{GPU-Fuzz} generated on average $51{,}860\pm 1{,}559$ test cases and uncovered $106\pm 8$ real bugs excluding out-of-memory errors, including $26\pm 5$ critical memory errors and $80\pm 7$ configuration errors. These memory errors represent severe security vulnerabilities that could result in data corruption, information leakage, or system crashes.

\begin{table}[htbp]
\centering
\caption{Comparative Results}
\label{tbl:comparison}
\footnotesize
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Metric} & \textbf{NNSmith} & \textbf{GPU-Fuzz} \\
\midrule
\textbf{Test Cases Generated} & $19{,}063\ \pm\ 360$ & $51{,}860\ \pm\ 1{,}559$ \\
\textbf{Total Bugs}\textsuperscript{*} & $296\ \pm\ 19$ & $106\ \pm\ 8$ \\
\midrule
\multicolumn{3}{@{}l}{\textbf{Bug Breakdown by Type}} \\
\hspace{1em}Memory Errors & 0 & $26\ \pm\ 5$ \\
\hspace{1em}Configuration Errors & 0 & $80\ \pm\ 7$ \\
\hspace{1em}Inconsistencies & $293\ \pm\ 19$ & 0 \\
\hspace{1em}Exceptions & $3\ \pm\ 1$ & 0 \\
\midrule
\textbf{Runtime} & \multicolumn{2}{c}{4 GPU-hours each} \\
\bottomrule
\multicolumn{3}{@{}l}{\scriptsize\textsuperscript{*}GPU-Fuzz total excludes out-of-memory errors.} \\
\multicolumn{3}{@{}l}{\scriptsize\textsuperscript{**}NNSmith and GPU-Fuzz results are mean $\pm$ std over 5 independent runs.} \\
\end{tabular}%
\end{table}

\parh{Key Findings.} 
Our analysis reveals two critical insights. First, \textsc{GPU-Fuzz} generated nearly three times more test cases than NNSmith, demonstrating the efficiency of constraint-guided parameter fuzzing in systematically exploring the operator parameter space. Second, \textsc{GPU-Fuzz} uncovered $26\pm 5$ memory errors that pose security risks, while NNSmith's findings were primarily numerical precision issues that typically do not threaten memory safety. This demonstrates that \textsc{GPU-Fuzz} addresses a blind spot in GPU memory security testing that existing DL fuzzers frequently miss. The two approaches are complementary: NNSmith excels at uncovering compiler-related bugs and numerical inconsistencies, while \textsc{GPU-Fuzz} fills the gap in GPU memory security testing at the operator parameter level.

\subsection{Case Study}
\label{sec:case_study}
To illustrate the practical utility of \textsc{GPU-Fuzz}, we present a minimal proof-of-concept (PoC) for a memory corruption bug uncovered in PyTorch's \texttt{ConvTranspose2d} operator. The PoC is shown in \F~\ref{fig:poc_code}.

\begin{figure}[htbp]
\centering
\vspace{-0.2em}
\includegraphics[width=0.9\columnwidth]{figs/code.pdf}
\vspace{-0.4em}
\caption{A minimal PoC in Python and the corresponding CUDA implementation that triggers a memory bug in PyTorch's \texttt{ConvTranspose2d}.}
\Description{A code snippet showing a minimal proof-of-concept in Python that triggers a memory corruption bug in PyTorch's ConvTranspose2d operator, along with the corresponding CUDA code demonstrating an integer overflow when calculating the total number of elements, leading to invalid memory access.}
\label{fig:poc_code}
\vspace{-0.2em}
\end{figure}

The key to triggering this bug lies in the parameter combination automatically generated by our fuzzer, particularly the extremely large stride value of $(200, 200)$ combined with input dimensions of $(10, 40000, 2)$. 
While these values are semantically valid according to PyTorch's API, they represent a corner case that is unlikely to be covered by manual tests. 
As illustrated in \F~\ref{fig:poc_code}, the root cause is an integer overflow in the C++ host code: when calculating the total number of elements for the CUDA kernel, a 64-bit integer value is cast to a 32-bit integer, which causes truncation. 
This overflowed value is then used to calculate the CUDA grid dimensions, resulting in an undersized grid that cannot cover all required memory operations. 
When the \texttt{col2im\_kernel} executes, threads calculate 64-bit indices that exceed the actual allocated buffer size, leading to out-of-bounds memory writes. 

\begin{figure}[htbp]
    \centering
    \vspace{-0.2em}
    \includegraphics[width=0.8\columnwidth]{figs/log.pdf}
    \vspace{-0.4em}
    \caption{The error message for the PoC.}
    \Description{An error log showing the error message for the proof-of-concept code in the previous figure.}
    \label{fig:poc_log}
    \vspace{-0.2em}
    \end{figure}
    
As shown in \F~\ref{fig:poc_log}, compute-sanitizer detects that a CUDA thread attempts to write to an out-of-bounds address, which is before the nearest valid allocation. 
This type of silent memory corruption is a severe bug that can lead to incorrect results or unpredictable behavior without causing an explicit Python crash, and demonstrates the ability of \textsc{GPU-Fuzz} to systematically uncover severe, hidden bugs in mature deep learning frameworks by exploring non-trivial parameter spaces.

