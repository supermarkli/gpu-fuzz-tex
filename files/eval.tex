\section{Evaluation}
\label{sec:eval}

In this section, we evaluate the effectiveness and efficiency of GPU-Fuzz. We aim to answer the following research questions (RQs):
\begin{itemize}
    \item \textbf{RQ1:} How effective is GPU-Fuzz in discovering real-world bugs in major deep learning frameworks?
    \item \textbf{RQ2:} How efficient is the structured generative fuzzing strategy of GPU-Fuzz?
    \item \textbf{RQ3:} How does GPU-Fuzz's log-based approach facilitate bug reproduction and analysis?
\end{itemize}

\subsection{Experimental Setup}
\label{sec:setup}
All experiments were conducted on a server with the configuration detailed in Table~\ref{tbl:setup}. We established isolated Conda environments for each of the three target frameworks---PyTorch, TensorFlow, and PaddlePaddle---to manage their specific dependencies. The core hardware, operating system, and NVIDIA driver were consistent across all tests.

\begin{table}[h!]
\centering
\caption{Experimental Environment Configuration.}
\label{tbl:setup}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{@{}ll@{}}
\toprule
\textbf{Component} & \textbf{Specification} \\ \midrule
\multicolumn{2}{@{}l}{\textbf{Hardware}} \\
\hspace{1em}CPU & 2 x Intel Xeon Silver 4510 (24 cores / 48 threads total) \\
\hspace{1em}GPU & NVIDIA H100 PCIe \\
\midrule
\multicolumn{2}{@{}l}{\textbf{Software (Common)}} \\
\hspace{1em}Operating System & Ubuntu 24.04.2 LTS \\
\hspace{1em}NVIDIA Driver & 580.82.07 \\
\hspace{1em}CUDA Runtime & 12.8.93 \\
\hspace{1em}Python & 3.11.13 \\
\midrule
\multicolumn{2}{@{}l}{\textbf{Frameworks (in separate Conda environments)}} \\
\hspace{1em}PyTorch & PyTorch 2.3.1+cu121 with cuDNN 8.9.2.26 \\
\hspace{1em}TensorFlow & 2.20.0, with cuDNN 9.13.0.50 \\
\hspace{1em}PaddlePaddle & 2.6.1 \\
\bottomrule
\end{tabular}%
}
\end{table}


\subsection{RQ1: Bug Discovery Effectiveness}

Over the course of our evaluation, GPU-Fuzz discovered a total of 14 unique, previously unknown bugs across the three frameworks. Table~\ref{tbl:bugs} presents a summary of these findings. The bugs span a wide range of types, from memory corruption errors deep within CUDA kernels to integer overflows and incorrect API parameter handling at the framework level. Notably, 12 of these bugs were silent errors that would not have caused a crash at the Python level and were only detectable thanks to \texttt{compute-sanitizer}. At the time of writing, we have reported all findings by opening issues in the corresponding repositories.

\begin{table*}[htbp]
\centering
\caption{Summary of Bugs Discovered by GPU-Fuzz.}
\label{tbl:bugs}
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}llllll@{}}
\toprule
\textbf{ID} & \textbf{Framework} & \textbf{Operator} & \textbf{Bug Type} & \textbf{Root Cause} & \textbf{Note} \\ \midrule
poc1 & PyTorch & \texttt{conv\_transpose2d} & OOB Global Write & Incorrect grid dimension calculation & CUBLAS fail \\
poc2 & PyTorch & \texttt{bmm\_sparse} & Misaligned Global Write & Incorrect pointer arithmetic in CUSPARSE & Silent error \\
poc3 & PaddlePaddle & \texttt{conv2d\_transpose} & Precondition Violation & Integer overflow in tensor dimension calc. & CPU-side error \\
poc4 & PaddlePaddle & \texttt{conv3d\_transpose} & Illegal Instruction & Invalid parameters passed to cuDNN kernel & CUDNN fail \\
poc5 & PyTorch & \texttt{adaptive\_avg\_pool2d} & OOB Global Write & Flawed boundary checks in CUDA kernel & Silent error \\
poc6 & PyTorch & \texttt{replication\_pad2d} & OOB Global Write & Incorrect grid dimension calculation & Silent error \\
poc7 & PyTorch & \texttt{adaptive\_max\_pool2d} & OOB Global Write & Flawed boundary checks in CUDA kernel & Silent error \\
poc8/9 & TensorFlow & \texttt{Conv2D} & OOB Global Read & Incorrect index calculation in kernel & Silent, downstream fails \\
poc11 & TensorFlow & \texttt{Conv2D} & Integer Overflow & Overflow in launch config calculation & CPU assertion fail \\
poc12 & PaddlePaddle & \texttt{conv2d\_transpose} & Bad API Parameter & Invalid parameter combination passed to cuDNN & CUDNN\_STATUS\_BAD\_PARAM \\
poc13 & PaddlePaddle & \texttt{conv2d\_transpose} & Invalid Launch Config & Incorrect grid/block dimension calculation & \texttt{cudaErrorInvalidConfiguration} \\
poc14 & PyTorch & \texttt{conv\_transpose3d} & OOB Shared Read & Incorrect index calculation for shared memory & Silent error \\
poc15 & PyTorch & \texttt{reflection\_pad1d} & Invalid Launch Config & Integer overflow in \texttt{torch.compile} symint logic & \texttt{cudaErrorInvalidConfiguration} \\
\bottomrule
\end{tabular}%
}
\end{table*}

The results clearly demonstrate that GPU-Fuzz is highly effective at finding critical, real-world bugs. Its ability to generate semantically valid inputs allows it to penetrate the framework's defenses and stress-test the complex, often manually-optimized CUDA code in the backend, which remains a significant source of vulnerabilities.

\subsection{RQ2: Efficiency of Constraint-Based Fuzzing}
GPU-Fuzz's constraint-based approach is designed to be more efficient than naive random fuzzing. By modeling the valid parameter space of an operator using Z3, we ensure that every generated test case is semantically correct and passes the framework's initial API-level validation checks. This allows the fuzzer to focus its resources on executing code in the GPU backend, which is the primary target of our investigation, rather than wasting cycles on invalid inputs that are immediately rejected.

While a quantitative comparison against a baseline random fuzzer was not conducted in this study, the logical advantage is clear. The parameter space for deep learning operators is vast and sparse; for instance, the relationships between input shape, kernel size, stride, and padding in a convolution are strict. A naive fuzzer would have a vanishingly small probability of generating a valid combination. In contrast, GPU-Fuzz achieves a near-100\% rate of valid test cases by construction, making it a far more practical approach for discovering deep bugs in a reasonable timeframe. A full quantitative evaluation of this efficiency gain remains an important direction for future work.

\subsection{RQ3: Log-based Bug Reproduction}
A key challenge in fixing GPU bugs is the difficulty of reproduction. To address this, GPU-Fuzz implements a comprehensive logging mechanism that facilitates a semi-automated reproduction workflow. For every test case executed, the system saves a detailed log containing the exact operator, all input parameters, the random seed used for any internal stochastic decisions, and the full input tensors.

When a crash is detected by an external tool like \texttt{compute-sanitizer}, these logs provide all the necessary information to deterministically reproduce the failure. We have developed reproducer scripts (located in the \texttt{poc/} directory) that read these log files. By using the logged random seed and parameters, the script can faithfully reconstruct the exact state that triggered the bug, providing a reliable and minimal test case for developers. This process significantly reduces the time and effort required for bug analysis, bridging the gap from initial crash detection to root-cause analysis.