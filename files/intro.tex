\section{Introduction}
\label{sec:intro}

GPUs have become the cornerstone of modern computing, especially in the realm of artificial intelligence. Deep learning frameworks such as PyTorch, TensorFlow, and PaddlePaddle, which are the core software layer built upon GPUs, directly impact the reliability of countless applications across various domains. The GPU backends of these frameworks are extraordinarily complex, comprising a vast amount of code from low-level libraries like cuDNN and cuBLAS, as well as numerous handwritten CUDA kernels. This complexity makes them a fertile ground for security vulnerabilities and stability issues, where even a minor computation error or memory out-of-bounds access can lead to severe consequences.

However, traditional fuzzing methodologies prove ineffective in this context. The random data streams they generate are almost invariably rejected by the frameworks' stringent input validation checks on tensor shapes and data types. As a result, these fuzzers fail to reach the deeper computational logic within the GPU kernels, leaving a critical attack surface untested.

Our key insight is that to effectively test the GPU backend, the fuzzer must understand and respect the semantic constraints of the operators. For example, the relationship between input and output shapes in a convolutional layer is mathematically defined; generating inputs that adhere to these rules is crucial for bypassing frontend validation and stress-testing the underlying CUDA kernels.

Based on this insight, we have designed and implemented \textbf{GPU-Fuzz}, a novel, cross-framework fuzzing system. GPU-Fuzz automates the entire closed-loop process of constraint modeling, solving, test case generation, cross-framework execution, and crash reproduction. It systematically translates the semantic rules of deep learning operators into formal constraints, uses the Z3 SMT solver to generate valid and boundary-aware inputs, and then executes these tests on the GPU backends of major deep learning frameworks.

The main contributions of this paper are as follows:
\begin{itemize}
    \item We propose and implement GPU-Fuzz, the first system to apply Z3 constraint solving to the problem of cross-framework GPU fuzzing for deep learning applications.
    \item We demonstrate the effectiveness of our approach by discovering a significant number of previously unknown bugs in widely-used frameworks like PyTorch, TensorFlow, and PaddlePaddle. 
    \item We provide a comprehensive, open-source dataset of real-world bugs discovered by our tool, complete with detailed logs and reproducer scripts, which can serve as a valuable resource for developers and security researchers.
    \item We argue that our constraint-solving approach is significantly more efficient than traditional random fuzzing by ensuring a high ratio of valid test cases that reach the GPU backend.
\end{itemize}
