\section{Introduction}
\label{sec:intro}

The security of GPU computations within deep learning (DL) frameworks like PyTorch and TensorFlow is critical. An imminent and important threat in this domain is the prevalence of GPU memory errors, a severe and insidious class of vulnerabilities stemming from the low-level CUDA kernels that implement DL operators. These errors, such as out-of-bounds access or misaligned memory addressing, can lead not only to system crashes but also to silent data corruption, posing a significant threat to the reliability and security of AI applications.

However, discovering these memory-related bugs remains a profound challenge. Existing fuzzers for DL systems are primarily designed to find logical bugs in the compiler stack by generating entire neural networks. This network-level focus, while effective for compiler testing, is ill-suited for uncovering memory errors that lie deep within the parameter space of individual operators.

Our key insight is that uncovering GPU memory errors requires a shift in focus from the network structure to the operator parameters and memory layout. The precise combination of tensor shapes, data types, strides, and other parameters dictates the memory access patterns within a CUDA kernel. To effectively find memory bugs, a fuzzer must be able to reason about these intricate constraints and generate inputs that specifically stress the memory management logic.

To this end, we designed and implemented \textsc{Gpu-Fuzz}, a novel fuzzer specifically engineered to address the threat of GPU memory errors. Unlike structure-oriented fuzzers, \textsc{Gpu-Fuzz} focuses on the operator level. It translates the complex semantic and memory-related rules of DL operators into formal constraints, which are then solved to generate precise inputs that probe memory-related boundary conditions. This constraint-guided approach enables \textsc{Gpu-Fuzz} to bypass the frameworks' frontend validation and directly stress-test the low-level CUDA kernels for memory safety.

The main contributions of this paper are as follows:
\begin{itemize}
    \item We propose a new fuzzing methodology that targets GPU memory errors by systematically exploring the operator parameter space, a dimension orthogonal to existing network structure fuzzers.
    \item We design and implement \textsc{Gpu-Fuzz}, a system that embodies this methodology by leveraging constraint solving to automatically generate test cases that probe memory-related boundary conditions in low-level CUDA kernels.
    \item We demonstrate the effectiveness of \textsc{Gpu-Fuzz} by discovering 14 previously unknown bugs, the majority being severe memory errors, in major DL frameworks and provide public minimal reproducers to benefit the community.
\end{itemize}
