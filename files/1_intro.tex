\section{Introduction}
\label{sec:intro}

GPUs are now an indispensable component of deep learning (DL) frameworks like PyTorch~\cite{paszke2019pytorch} and TensorFlow~\cite{abadi2016tensorflow}. However, the correctness of GPU computations are often threatened by memory corruptions, an insidious class of bugs stemming from the low-level CUDA kernels~\cite{nickolls2008scalable}. These errors, such as out-of-bounds access or misaligned memory addressing, can lead not only to system crashes but also to silent data corruption~\cite{fiala2012detection}, posing a significant threat to the reliability and security of AI applications.

However, locating these memory-related bugs remains a profound challenge. Existing fuzzers for DL systems are primarily designed to find arithmetic miscomputions in the DL compilers by generating diverse neural networks with different structures~\cite{liu2023nnsmith}. This approach, while effective for compiler testing, is ill-suited for uncovering memory errors due to the lack of exploration of the operator parameter space.

Our key insight is that uncovering GPU memory errors requires a shift in focus from the network structure to the operator parameters and memory layout. The precise combination of tensor shapes, data types, strides, and other parameters dictates the memory access patterns within a CUDA kernel. To effectively find memory bugs, a fuzzer must be able to reason about these intricate patterns and generate inputs that systematically explore the parameter space.

To this end, we designed and implemented \textsc{GPU-Fuzz}, a novel fuzzer specifically engineered to locate these memory-related bugs. Unlike structure-oriented fuzzers such as NNSmith~\cite{liu2023nnsmith}, \textsc{GPU-Fuzz} focuses on the operator level. It translates the complex semantic and memory-related rules of DL operators into formal constraints, which are then solved to generate diversified inputs that probe memory-related boundary conditions. This constraint-guided approach~\cite{cadar2008klee} enables \textsc{GPU-Fuzz} to effectively stress-test the low-level CUDA kernels for memory safety.

The main contributions of this paper are as follows:
\begin{itemize}
    \item We propose a new fuzzing approach that targets GPU memory errors by systematically exploring the operator parameter space, a dimension orthogonal to existing DL fuzzers~\cite{liu2023nnsmith}.
    \item We design and implement \textsc{GPU-Fuzz}, a system that leverages constraint solving to automatically generate test cases that probe memory-related boundary conditions in low-level CUDA kernels.
    \item We demonstrate the effectiveness of \textsc{GPU-Fuzz} by uncovering 13 previously unknown bugs, in major DL frameworks like PyTorch.
\end{itemize}
