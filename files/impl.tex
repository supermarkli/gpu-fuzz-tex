\section{Implementation}
\label{sec:impl}
Our implementation of GPU-Fuzz consists of approximately 2,000 lines of Python code. The system is orchestrated by a central controller that manages the fuzzing loop, which includes test case generation, execution, and logging.

\parh{Constraint Library and Generation.}
Our constraint library, implemented in \texttt{gen/ops.py}, currently provides models for 11 families of operators, including various types of convolutions, pooling, and element-wise arithmetic operations. Table~\ref{tab:operator_families} lists the supported operator families.

\begin{table*}[t]
\centering
\caption{Supported Operator Families and Specific Operators in GPU-Fuzz}
\label{tab:operator_families}
\begin{tabularx}{\textwidth}{lllX}
\toprule
\textbf{Category} & \textbf{Operator Family} & \textbf{Specific Operators} & \textbf{Notes / Examples} \\
\midrule
\multirow{2}{*}{Convolution} & \multirow{2}{*}{Convolution} & Conv (1d, 2d, 3d) & Covers 1D, 2D, and 3D standard convolutions. \\
& & ConvTranspose (1d, 2d, 3d) & Covers 1D, 2D, and 3D transposed convolutions. \\
\midrule
\multirow{6}{*}{Pooling} & \multirow{6}{*}{Pooling} & MaxPool (1d, 2d, 3d) & \\
& & AvgPool (1d, 2d, 3d) & \\
& & FractionalMaxPool (2d, 3d) & \\
& & LPPool & \\
& & AdaptiveAvgPool (1d, 2d, 3d) & \\
& & AdaptiveMaxPool (1d, 2d, 3d) & \\
\midrule
\multirow{5}{*}{Padding} & \multirow{5}{*}{Padding} & ConstantPad & \\
& & ReflectionPad & \\
& & ReplicationPad & \\
& & ZeroPad & \\
& & CircularPad & \\
\midrule
\multirow{2}{*}{Element-Wise} & Unary & (abs, sin, sqrt, ...) & Includes absolute value, sine, square root, etc. \\
& Binary & (add, sub, mul, ...) & Includes element-wise addition, subtraction, multiplication, etc. \\
\midrule
Matrix Ops & MatMul & MatMul / BMM & Standard and batched matrix multiplication. \\
\bottomrule
\end{tabularx}
\end{table*}

Building a model for a new operator family, such as \texttt{AbsConv}, typically requires 100-150 lines of code to define its parameters as Z3 symbolic variables and encode the mathematical relationships between them (e.g., the output size formula) as Z3 constraints. The \texttt{materialize} method in each operator class then iterates through valid solutions found by the Z3 solver.

\parh{Framework Instantiation.} The parameters generated by the Z3 solver are saved to a JSON file. The \texttt{model\_gen.py} script reads this file and materializes the abstract test case into code for a specific framework (PyTorch, TensorFlow, or PaddlePaddle). It uses the framework's native Python API (e.g., \texttt{torch.nn.Conv2d}) to construct the operator with the solved parameters, creates tensor objects with the specified shapes, populates them with random data, and executes the operation on the GPU.

\parh{Crash Detection with Compute Sanitizer.} A key technical challenge was reliably automating crash detection. Our main controller script, \texttt{controller.py}, uses the \texttt{pexpect} library to solve this. It spawns the test case execution script (\texttt{model\_gen.py}) as a child process, but wraps the entire command with NVIDIA's \texttt{compute-sanitizer}. The controller monitors the output for specific error patterns that \texttt{compute-sanitizer} emits upon detecting a GPU kernel error. When such a pattern is matched, it terminates the process and archives the logs for reproduction.
