\section{System Design}
\label{sec:design}

This section details the architecture of GPU-Fuzz. As illustrated in Figure~\ref{fig:arch}, the system is designed around a data flow that seamlessly connects constraint-based test case generation with cross-framework execution, monitoring, and log-based reproduction.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\linewidth]{figs/arch.pdf} % Note: You need to generate arch.pdf from draw/arch.mermaid
	\caption{The architecture of the GPU-Fuzz system.}
	\label{fig:arch}
\end{figure}

\subsection{Constraint Library and Operator Modeling}
The foundation of GPU-Fuzz is its ability to generate semantically valid inputs. This is achieved through a Constraint Library that models the operational semantics of deep learning operators. For each target operator (e.g., convolution, pooling, matrix multiplication), we define a set of constraints that capture the legitimate relationships between its parameters, such as tensor shapes, data types, kernel sizes, strides, and padding. These constraints are expressed using the Z3 SMT solver's Python API, creating a framework-agnostic representation of the operator's contract. This approach ensures that any test case generated by the solver is, by construction, guaranteed to pass the framework's initial validation checks.

\subsection{Constraint Solving and Test Case Generation}
The core of the fuzzing loop resides in the test case generator. The process begins by randomly selecting an operator template from the Constraint Library. The generator then populates the template with randomized, but plausible, target dimensions and parameters. These parameters, along with the operator's formal constraints, are passed to the Z3 solver. The solver's task is to find a concrete assignment of values that satisfies all constraints. The result is a set of valid parameters (e.g., \texttt{input\_shape}, \texttt{kernel\_size}, \texttt{stride}) and the corresponding output tensor shape. This entire configuration is saved as a JSON file, representing an abstract, executable test case.

\subsection{Cross-Framework Execution and Monitoring}
Once a set of valid parameters is generated, the test case is materialized into an executable script for a target framework (PyTorch, TensorFlow, or PaddlePaddle). This script creates the necessary tensors, populates them with random data, and invokes the operator on the GPU.

The execution is monitored by NVIDIA's \texttt{compute-sanitizer}. This tool can detect a wide range of GPU-level errors, such as out-of-bounds memory accesses and race conditions, that would not typically cause a visible crash at the Python API level. When a bug is detected, \texttt{compute-sanitizer} terminates the process and generates a detailed report, which serves as our primary bug oracle.

\subsection{Log-based Reproduction}
A critical component of GPU-Fuzz is its comprehensive logging system, designed to ensure bug reproducibility. For every test case, the fuzzer records a detailed JSON log containing:
\begin{itemize}
    \item The target operator and framework.
    \item The exact set of parameters used (e.g., kernel size, stride, padding).
    \item The shapes of all input tensors.
    \item The random seed used for data generation and any other stochastic choices.
\end{itemize}
In addition to the JSON log, the complete input tensors are saved to separate files. When a crash occurs, this combination of logs provides a complete, self-contained record of the conditions that triggered the bug. A developer can then use a simple script to load these artifacts and deterministically reproduce the failure, significantly streamlining the debugging process.